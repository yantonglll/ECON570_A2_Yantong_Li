{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2140d5d7",
   "metadata": {},
   "source": [
    "## ECON 570 \n",
    "## Assignment 2\n",
    "## Instructor: Ida Johnsson\n",
    "## Name: Yantong Li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7257f92",
   "metadata": {},
   "source": [
    "### 1. Simulate a DGP where the outcome of interest depends on a randomly assigned treatment and some observed covariates. How does your estimate of the treatment effect parameter compare in the following two cases\n",
    "#### a. You do not control for any covariates\n",
    "#### b. You control for all the covariates that affect the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c327cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26189e27",
   "metadata": {},
   "source": [
    "### a. You do not control for any covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197e868",
   "metadata": {},
   "source": [
    "#### suppose our model is the following:\n",
    "$Y_i = a*T_i+e_i$, where $e_i \\sim N(0,\\sigma^2)$\n",
    "#### $a$ is the treatment effect, treatment takes values 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762dd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "    return Y\n",
    "\n",
    "def fn_generate_data(a,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \n",
    "    nvar = p+2\n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    \n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0\n",
    "    Yab = a*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    \n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n",
    "\n",
    "def fn_ahat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    ahat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_ahat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (ahat,se_ahat)\n",
    "\n",
    "def fn_run_experiments(a,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(a,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            ahat,se_ahat = fn_ahat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            \n",
    "            Yexp,T,X = fn_generate_data(a,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            ahat = res.params[0]\n",
    "            se_ahat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            \n",
    "            Yexp,T,X = fn_generate_data(a,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            ahat = res.params[0]\n",
    "            se_ahat = res.HC1_se[0]\n",
    "            \n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]    \n",
    "        lb = lb + [ahat-1.96*se_ahat]\n",
    "        ub = ub + [ahat+1.96*se_ahat]\n",
    "        \n",
    "    return (n_values,ahats,sehats,lb,ub)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat \n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    return (bias,rmse,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7f99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the DGP\n",
    "\n",
    "a = 3\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3443b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "Yexp,T = fn_generate_data(a,N,10,0,corr,conf = False)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "ahat,se_ahat = fn_ahat_means(Yt,Yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4d49dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1553471190512368, 0.19761989714303319)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahat,se_ahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e51ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = np.ones([N,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9d1d9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.719\n",
      "Method:                 Least Squares   F-statistic:                     254.9\n",
      "Date:                Tue, 08 Mar 2022   Prob (F-statistic):           5.09e-29\n",
      "Time:                        17:46:46   Log-Likelihood:                -139.69\n",
      "No. Observations:                 100   AIC:                             283.4\n",
      "Df Residuals:                      98   BIC:                             288.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             3.1553      0.198     15.967      0.000       2.763       3.548\n",
      "const         -0.2601      0.140     -1.861      0.066      -0.537       0.017\n",
      "==============================================================================\n",
      "Omnibus:                        1.798   Durbin-Watson:                   2.252\n",
      "Prob(Omnibus):                  0.407   Jarque-Bera (JB):                1.584\n",
      "Skew:                           0.308   Prob(JB):                        0.453\n",
      "Kurtosis:                       2.975   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.1553471190512368, 0.19761989714303319)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "# res.summary()\n",
    "print(res.summary())\n",
    "res.params[0], res.HC1_se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a95459",
   "metadata": {},
   "source": [
    "#### From above, we can see that when you just run the experiment once, the estimated coefficient could be misleading because when the noise contained in $e_i$ is big, we cannot tell whether the estimated coefficient is a good one or not. Therefore, we need to run a Monte Carlo simulation to see the distribution of estimated parameters and tell whether the model produces good enough estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3eb14d",
   "metadata": {},
   "source": [
    "### Running a Monte Carlo simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb8b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1190.96it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:13<00:00, 148.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running a Monte Carlo simulation:\n",
    "\n",
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    ahats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(a,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        ahat,se_ahat = fn_ahat_means(Yt,Yc)\n",
    "        ahats = ahats + [ahat]\n",
    "        sehats = sehats + [se_ahat]\n",
    "    estDict[N] = {\n",
    "        'ahat':np.array(ahats).reshape([len(ahats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf133f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.006806652228300948, RMSE=0.20186280107828916, size=0.0525\n",
      "N=1000: bias=0.0004184398140799954, RMSE=0.06272696543272394, size=0.0485\n"
     ]
    }
   ],
   "source": [
    "a0 = a*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(a0,results['ahat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdda119",
   "metadata": {},
   "source": [
    "### real-life situation that might be consistent with the DGP:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
